{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21a1864",
   "metadata": {},
   "source": [
    "# Homework - 01\n",
    "                                                                                            CAP 6629 Reinforcement Learning\n",
    "                                                                                                         Dr. Chang-Hwan Lee\n",
    "\n",
    "                                                                                                        by - Rishabh Lingam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bef50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f6e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 7, 7\n",
    "no_states = rows * cols\n",
    "no_actions = 4\n",
    "LEFT, UP, RIGHT, DOWN = 0, 1, 2, 3\n",
    "START = [0, 48]\n",
    "STOP = [25, 38]\n",
    "Blocks = [2, 5, 7, 9, 17, 20, 22, 26, 31, 37, 39, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d9cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def get_row_col_index_0(position, t_rows, t_cols):\n",
    "    row_idx = position // t_cols\n",
    "    col_idx = (position % t_cols)\n",
    "    return row_idx, col_idx\n",
    "\n",
    "def get_row_col_index(position):\n",
    "    return get_row_col_index_0(position, rows, cols)\n",
    "\n",
    "def get_position_0(row_idx, col_idx, t_rows, t_cols):\n",
    "    if row_idx < 0 :\n",
    "        row_idx = 0\n",
    "    elif row_idx == t_rows:\n",
    "        row_idx = t_rows - 1\n",
    "    if col_idx < 0:\n",
    "        col_idx = 0\n",
    "    elif col_idx == t_cols:\n",
    "        col_idx = t_cols - 1\n",
    "    return (row_idx * t_cols) + (col_idx)\n",
    "\n",
    "def get_position(row_idx, col_idx):\n",
    "    return get_position_0(row_idx, col_idx, rows, cols)\n",
    "\n",
    "def can_go_left(position):\n",
    "    row_idx, col_idx = get_row_col_index(position)\n",
    "    lef_pos = get_position(row_idx, col_idx - 1)\n",
    "    return (col_idx != 0) and (lef_pos not in Blocks)\n",
    "\n",
    "def can_go_right(position):\n",
    "    row_idx, col_idx = get_row_col_index(position)\n",
    "    right_pos = get_position(row_idx, col_idx + 1)\n",
    "    return (col_idx != cols - 1) and (right_pos not in Blocks)\n",
    "\n",
    "def can_go_up(position):\n",
    "    row_idx, col_idx = get_row_col_index(position)\n",
    "    up_pos = get_position(row_idx - 1, col_idx)\n",
    "    return (row_idx != 0) and (up_pos not in Blocks)\n",
    "\n",
    "def can_go_down(position):\n",
    "    row_idx, col_idx = get_row_col_index(position)\n",
    "    down_pos = get_position(row_idx + 1, col_idx)\n",
    "    return (row_idx != rows - 1) and (down_pos not in Blocks)\n",
    "\n",
    "def get_possible_action_state(position):\n",
    "    row_idx, col_idx = get_row_col_index(position)\n",
    "    actions, states = [], []\n",
    "    \n",
    "    if can_go_left(position):\n",
    "        actions.append(LEFT)\n",
    "        states.append(get_position(row_idx, col_idx-1))\n",
    "    if can_go_up(position):\n",
    "        actions.append(UP)\n",
    "        states.append(get_position(row_idx-1, col_idx))\n",
    "    if can_go_right(position):\n",
    "        actions.append(RIGHT)\n",
    "        states.append(get_position(row_idx, col_idx + 1))\n",
    "    if can_go_down(position):\n",
    "        actions.append(DOWN)\n",
    "        states.append(get_position(row_idx+1, col_idx))\n",
    "        \n",
    "    return actions, states\n",
    "\n",
    "def get_string_policy(policy):\n",
    "    n = len(policy)\n",
    "    string_policy = np.chararray(n, itemsize=10, unicode=True)\n",
    "    for s in range(n):\n",
    "        max_idx = np.argmax(policy[s])\n",
    "        if max_idx == 0:\n",
    "            string_policy[s] = 'LEFT'\n",
    "        elif max_idx == 1:\n",
    "            string_policy[s] = 'UP'\n",
    "        elif max_idx == 2:\n",
    "            string_policy[s] = 'RIGHT'\n",
    "        elif max_idx == 3:\n",
    "            string_policy[s] = 'DOWN'\n",
    "    \n",
    "    string_policy[START] = 'START'\n",
    "    string_policy[STOP] = 'STOP'\n",
    "    string_policy[Blocks] = 'BLOCK'\n",
    "    return string_policy\n",
    "\n",
    "def get_as_table(policy):\n",
    "    pTable = PrettyTable()\n",
    "    pTable.clear()\n",
    "    pol_temp = policy.reshape((rows, cols))\n",
    "    n = len(pol_temp)\n",
    "    for i in range(n):\n",
    "        pTable.add_row(pol_temp[i], divider=True)\n",
    "    pTable.header = False\n",
    "    return pTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c9e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition probability is |S| x |S'| x |A| array\n",
    "# T[i][j][k]= prob. moving from state i to j when doing action k\n",
    "# moving out of boundary or to block stays in current state\n",
    "\n",
    "T_deterministic = np.zeros((no_states, no_states, no_actions))\n",
    "\n",
    "for position in range(0, no_states):\n",
    "    row_idx, col_idx = get_row_col_index(position)\n",
    "        \n",
    "    left_pos = get_position(row_idx, col_idx - 1)\n",
    "    right_pos = get_position(row_idx, col_idx + 1)\n",
    "    up_pos = get_position(row_idx - 1, col_idx)\n",
    "    down_pos = get_position(row_idx + 1, col_idx)\n",
    "\n",
    "    T_deterministic[position, left_pos, LEFT] = 1\n",
    "    T_deterministic[position, up_pos, UP] = 1\n",
    "    T_deterministic[position, right_pos, RIGHT] = 1\n",
    "    T_deterministic[position, down_pos, DOWN] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d9de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2) probabiistic transition    \n",
    "#  complete T matrix for probabilistic transition\n",
    "\n",
    "T_probabilistic = np.zeros((no_states, no_states, no_actions))\n",
    "alpha = 0.05\n",
    "for position in range(0, no_states):\n",
    "    row_idx, col_idx = get_row_col_index(position)\n",
    "    \n",
    "    left_pos = get_position(row_idx, col_idx - 1)\n",
    "    right_pos = get_position(row_idx, col_idx + 1)\n",
    "    up_pos = get_position(row_idx - 1, col_idx)\n",
    "    down_pos = get_position(row_idx + 1, col_idx)\n",
    "    \n",
    "    T_probabilistic[position, left_pos, LEFT] = 1 - (4 * alpha)\n",
    "    a, s = get_possible_action_state(left_pos)\n",
    "    for i in range(len(s)):\n",
    "        T_probabilistic[s[i], left_pos, a[i]] = alpha\n",
    "    \n",
    "    T_probabilistic[position, up_pos, UP] = 1 - (4 * alpha)\n",
    "    a, s = get_possible_action_state(up_pos)\n",
    "    for i in range(len(s)):\n",
    "        T_probabilistic[s[i], up_pos, a[i]] = alpha\n",
    "    \n",
    "    T_probabilistic[position, right_pos, RIGHT] = 1 - (4 * alpha)\n",
    "    a, s = get_possible_action_state(right_pos)\n",
    "    for i in range(len(s)):\n",
    "        T_probabilistic[s[i], right_pos, a[i]] = alpha\n",
    "    \n",
    "    T_probabilistic[position, down_pos, DOWN] = 1 - (4 * alpha)\n",
    "    a, s = get_possible_action_state(down_pos)\n",
    "    for i in range(len(s)):\n",
    "        T_probabilistic[s[i], down_pos, a[i]] = alpha  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082d6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-3) Reward function: |S| x |A| array\n",
    "# R[i][j]= reward from state i and action j\n",
    "# each move generates -1 reward\n",
    "\n",
    "R = np.full((no_states, no_actions), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "730ba8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b295c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy: |S| x |A| array\n",
    "#P[i][j]= prob of choosing action j in state i\n",
    "# 2-1) initialize policy P with uniform policy\n",
    "\n",
    "uniform_P = np.full((no_states, no_actions), 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e3cc439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2) implement prediction (policy evaluation)\n",
    "# compute V values from a policy\n",
    "# implement prediction(policy evaluation) algorithm in slide page 7.\n",
    "\n",
    "def policy_eval(policy, max_iter, V, T):\n",
    "    for i in range(max_iter):\n",
    "        V_temp = np.zeros(no_states)\n",
    "        for s in range(no_states):\n",
    "            v_s = 0\n",
    "            for action in range(no_actions):\n",
    "                q_sa = 0\n",
    "                for s_prime in range(no_states):\n",
    "                    q_sa += T[s, s_prime, action] * V[s_prime]\n",
    "                q_sa *= gamma\n",
    "                q_sa += R[s, action]\n",
    "                q_sa *= policy[s, action]\n",
    "                v_s += q_sa\n",
    "            V_temp[s] = np.round(v_s, 4)\n",
    "            V_temp[STOP] = 0\n",
    "        V = np.copy(V_temp)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97990692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2) implement prediction (policy evaluation)\n",
    "# compute V values from a policy\n",
    "# implement prediction(policy evaluation) algorithm in slide page 7.\n",
    "\n",
    "def policy_eval_max(V, max_iter, T):\n",
    "    for i in range(max_iter):\n",
    "        V_temp = np.zeros(no_states)\n",
    "        for s in range(no_states):\n",
    "            v_s = []\n",
    "            for action in range(no_actions):\n",
    "                q_sa = 0\n",
    "                for s_prime in range(no_states):\n",
    "                    q_sa += T[s, s_prime, action] * V[s_prime]\n",
    "                q_sa *= gamma\n",
    "                q_sa += R[s, action]\n",
    "                v_s.append(q_sa)\n",
    "            V_temp[s] = np.round(np.max(v_s), 4)\n",
    "            V_temp[STOP] = 0\n",
    "        if np.sum(V == V_temp) == no_states:\n",
    "            break    \n",
    "        V = np.copy(V_temp)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5caa90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-3) implement policy improvement with V value using greedy method\n",
    "# The formula for choosing the best action using V value is given in question.\n",
    "\n",
    "def extract_policy(V):\n",
    "    '''\n",
    "    Procedure to extract a policy from a value function\n",
    "    pi <-- argmax_a R^a + gamma T^a V\n",
    "\n",
    "    Inputs:\n",
    "    V -- Value function: array of |S| entries\n",
    "\n",
    "    Output:\n",
    "    policy -- Policy array P\n",
    "    '''\n",
    "\n",
    "    # initialize random(uniform) policy\n",
    "    new_policy = np.zeros((no_states, no_actions))\n",
    "    \n",
    "    for s in range(no_states):\n",
    "        actions, states = get_possible_action_state(s)\n",
    "        max_idx = np.argmax(V[states])\n",
    "        max_state = states[max_idx]\n",
    "        max_act = actions[max_idx]\n",
    "        new_policy[s, max_act] = 1\n",
    "\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdf3b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-4) implement policy iteration method\n",
    "# implement policy iteration in slide page 13\n",
    "\n",
    "def policy_iter(in_policy, max_iter, T):\n",
    "    \n",
    "    '''    Policy iteration procedure: alternate between \n",
    "    1) policy evaluation (solve V^pi = R^pi + gamma T^pi V^pi) and \n",
    "    2) policy improvement (pi <-- argmax_a R^a + gamma T^a V^pi).\n",
    "\n",
    "    Inputs:\n",
    "    in_policy -- Initial policy\n",
    "    max_iter -- maximum # of iterations: scalar (use a large number)\n",
    "\n",
    "    Outputs: \n",
    "    policy -- Policy P\n",
    "    V -- Value function: array of |S| entries\n",
    "    no_iter -- the actual # of iterations peformed by policy iteration: scalar\n",
    "    '''\n",
    "\n",
    "    # Initialization P and V using np.zeros\n",
    "    P = in_policy\n",
    "    no_iter = 0\n",
    "    V = np.zeros(no_states)\n",
    "    for i in range(max_iter):\n",
    "        no_iter += 1\n",
    "        V = policy_eval(P, 50, V, T)\n",
    "        P_temp = extract_policy(V)\n",
    "        if np.sum(P == P_temp) == (no_states * no_actions):\n",
    "            break\n",
    "        P = np.copy(P_temp)\n",
    "\n",
    "    return P, V, no_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1340744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-5) implement value iteration method\n",
    "# implement value iteration in slide page 23\n",
    "def value_iter(in_V, max_iter, T):\n",
    "    '''\n",
    "    Value iteration procedure\n",
    "    V <-- max_a R^a + gamma T^a V\n",
    "\n",
    "    Inputs:\n",
    "    in_V -- Initial value function: array of |S| entries\n",
    "    max_iter -- limit on the # of iterations: scalar (use large number)\n",
    "\n",
    "    Outputs: \n",
    "    V -- Value function: array of |S| entries\n",
    "    no_iter -- the actual # of iterations peformed by policy iteration: scalar\n",
    "    '''\n",
    "        \n",
    "    # Initialization V using np.zeros\n",
    "    V = in_V\n",
    "    no_iter = 0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        no_iter += 1\n",
    "        V_temp = policy_eval_max(V, 1, T)\n",
    "        if np.sum(V == V_temp) == no_states:\n",
    "            break\n",
    "        V = np.copy(V_temp)\n",
    "        \n",
    "    return [V, no_iter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c9784a",
   "metadata": {},
   "source": [
    "## Deterministic Transition Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1c3daa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- POLICY ITERATION ---\n",
      "Total Iterations =  3\n",
      "\n",
      "State Vales:\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "|  -5.217 | -4.6856 | -4.0951 | -3.439 | -2.71 | -3.439 | -4.0951 |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "| -4.6856 | -4.0951 |  -3.439 | -2.71  |  -1.9 | -2.71  |  -3.439 |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "| -4.0951 |  -3.439 |  -2.71  |  -1.9  |  -1.0 |  -1.9  |  -2.71  |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "| -4.6856 |  -2.71  |   -1.9  |  -1.0  |  0.0  |  -1.0  |  -3.439 |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "| -4.0951 |  -3.439 |  -2.71  |  -1.0  |  -1.0 |  -1.9  |  -2.71  |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "| -4.0951 |  -3.439 |   -1.0  |  0.0   |  -1.0 | -2.71  |  -3.439 |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "|  -3.439 |  -2.71  |   -1.9  |  -1.0  |  -1.9 | -2.71  |  -3.439 |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "\n",
      "Policy:\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| START |  DOWN | BLOCK | RIGHT |  DOWN | BLOCK |  DOWN |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| BLOCK |  DOWN | BLOCK | RIGHT |  DOWN |  LEFT |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT | RIGHT |  DOWN | BLOCK |  DOWN |  LEFT | BLOCK |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "|   UP  | BLOCK | RIGHT | RIGHT |  STOP | BLOCK |  DOWN |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT | RIGHT |   UP  | BLOCK |   UP  |  LEFT |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT |  DOWN | BLOCK |  STOP | BLOCK |   UP  |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| BLOCK | RIGHT | RIGHT |   UP  |  LEFT |  LEFT | START |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "max_itr = 500\n",
    "\n",
    "print(\"--- POLICY ITERATION ---\")\n",
    "p_itr_p, p_itr_v, p_itr_itr = policy_iter(uniform_P, max_itr, T_deterministic)\n",
    "print(\"Total Iterations = \", p_itr_itr)\n",
    "print(\"\\nState Vales:\")\n",
    "print(get_as_table(p_itr_v))\n",
    "print(\"\\nPolicy:\")\n",
    "print(get_as_table(get_string_policy(p_itr_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a62792d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VALUE ITERATION ---\n",
      "Total Iterations =  8\n",
      "\n",
      "State Vales:\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "|  -5.217 | -4.6856 | -4.0951 | -3.439 | -2.71 | -3.439 | -4.0951 |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "| -4.6856 | -4.0951 |  -3.439 | -2.71  |  -1.9 | -2.71  |  -3.439 |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "| -4.0951 |  -3.439 |  -2.71  |  -1.9  |  -1.0 |  -1.9  |  -2.71  |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "|  -3.439 |  -2.71  |   -1.9  |  -1.0  |  0.0  |  -1.0  |   -1.9  |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "|  -3.439 |  -2.71  |   -1.9  |  -1.0  |  -1.0 |  -1.9  |  -2.71  |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "|  -2.71  |   -1.9  |   -1.0  |  0.0   |  -1.0 |  -1.9  |  -2.71  |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "|  -3.439 |  -2.71  |   -1.9  |  -1.0  |  -1.9 | -2.71  |  -3.439 |\n",
      "+---------+---------+---------+--------+-------+--------+---------+\n",
      "\n",
      "Policy:\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| START |  DOWN | BLOCK | RIGHT |  DOWN | BLOCK |  DOWN |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| BLOCK |  DOWN | BLOCK | RIGHT |  DOWN |  LEFT |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT | RIGHT |  DOWN | BLOCK |  DOWN |  LEFT | BLOCK |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  DOWN | BLOCK | RIGHT | RIGHT |  STOP | BLOCK |  DOWN |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT | RIGHT |   UP  | BLOCK |   UP  |  LEFT |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT |  LEFT | BLOCK |  STOP | BLOCK |   UP  |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| BLOCK |   UP  | RIGHT |   UP  |  LEFT |  LEFT | START |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "max_itr = 500\n",
    "\n",
    "print(\"--- VALUE ITERATION ---\")\n",
    "v_rand = np.zeros(no_states)\n",
    "v_itr = value_iter(v_rand, max_itr, T_deterministic)\n",
    "print(\"Total Iterations = \", v_itr[1])\n",
    "print(\"\\nState Vales:\")\n",
    "print(get_as_table(v_itr[0]))\n",
    "print(\"\\nPolicy:\")\n",
    "print(get_as_table(get_string_policy(extract_policy(v_itr[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a0a1ee",
   "metadata": {},
   "source": [
    "## Probabilistic Transition Probability Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55eb5019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- POLICY ITERATION ---\n",
      "Total Iterations =  4\n",
      "\n",
      "State Vales:\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.4096 | -3.3467 | -3.0414 | -2.8353 | -2.3589 | -2.6984 | -3.0079 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.2383 | -3.2593 | -2.7888 | -2.4844 | -1.8873 | -2.4844 | -2.7888 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.1087 | -2.9287 | -2.4844 | -1.7811 | -1.0849 | -1.8873 | -2.3589 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.3471 | -2.3589 | -1.8873 | -1.0849 |   0.0   |   -1.0  | -2.7892 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.0655 | -2.8688 | -2.4039 |   -1.0  |  -1.045 | -1.8576 | -2.3375 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.0786 |  -2.887 |   -1.0  |   0.0   |   -1.0  | -2.4473 | -2.8071 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "|  -2.758 | -2.4416 | -1.8299 |   -1.0  | -1.8299 | -2.4416 |  -2.758 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "\n",
      "Policy:\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| START |  DOWN | BLOCK | RIGHT |  DOWN | BLOCK |  DOWN |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| BLOCK |  DOWN | BLOCK | RIGHT |  DOWN |  LEFT |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT | RIGHT |  DOWN | BLOCK |  DOWN |  LEFT | BLOCK |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  DOWN | BLOCK | RIGHT | RIGHT |  STOP | BLOCK |  DOWN |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT | RIGHT |   UP  | BLOCK |   UP  |  LEFT |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT |  DOWN | BLOCK |  STOP | BLOCK |   UP  |   UP  |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| BLOCK | RIGHT | RIGHT |   UP  |  LEFT |  LEFT | START |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "max_itr = 500\n",
    "\n",
    "print(\"--- POLICY ITERATION ---\")\n",
    "p_itr_p, p_itr_v, p_itr_itr = policy_iter(uniform_P, max_itr, T_probabilistic)\n",
    "print(\"Total Iterations = \", p_itr_itr)\n",
    "print(\"\\nState Vales:\")\n",
    "print(get_as_table(p_itr_v))\n",
    "print(\"\\nPolicy:\")\n",
    "print(get_as_table(get_string_policy(p_itr_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "677b6855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- VALUE ITERATION ---\n",
      "Total Iterations =  14\n",
      "\n",
      "State Vales:\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.2978 | -3.2396 | -2.9669 | -2.7318 | -2.3589 | -2.6984 | -2.9428 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.1914 | -3.1105 | -2.7318 | -2.4053 | -1.8873 | -2.4388 | -2.7441 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -3.0436 | -2.8384 | -2.4101 | -1.7811 | -1.0849 | -1.8297 | -2.2384 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -2.6984 | -2.3589 | -1.8873 | -1.0849 |   0.0   |   -1.0  |  -1.72  |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "|  -2.742 | -2.4195 | -1.8049 |   -1.0  |  -1.045 | -1.8021 | -2.2975 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -2.3134 | -1.8241 |   -1.0  |   0.0   |   -1.0  | -1.8241 | -2.3134 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "| -2.6656 | -2.3134 |  -1.72  |   -1.0  |  -1.72  | -2.3134 | -2.6656 |\n",
      "+---------+---------+---------+---------+---------+---------+---------+\n",
      "\n",
      "Policy:\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| START |  DOWN | BLOCK | RIGHT |  DOWN | BLOCK |  DOWN |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| BLOCK |  DOWN | BLOCK | RIGHT |  DOWN |  DOWN |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  DOWN | RIGHT |  DOWN | BLOCK |  DOWN |  LEFT | BLOCK |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  DOWN | BLOCK | RIGHT | RIGHT |  STOP | BLOCK |  DOWN |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  DOWN | RIGHT |   UP  | BLOCK |   UP  |  LEFT |   UP  |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| RIGHT |  LEFT | BLOCK |  STOP | BLOCK |   UP  |  LEFT |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n",
      "| BLOCK | RIGHT | RIGHT |   UP  |  LEFT |  LEFT | START |\n",
      "+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "max_itr = 500\n",
    "\n",
    "print(\"--- VALUE ITERATION ---\")\n",
    "v_rand = np.zeros(no_states)\n",
    "v_itr = value_iter(v_rand, max_itr, T_probabilistic)\n",
    "print(\"Total Iterations = \", v_itr[1])\n",
    "print(\"\\nState Vales:\")\n",
    "print(get_as_table(v_itr[0]))\n",
    "print(\"\\nPolicy:\")\n",
    "print(get_as_table(get_string_policy(extract_policy(v_itr[0]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
